{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspellchecker in /Users/celys/Library/Python/3.9/lib/python/site-packages (0.6.3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "!pip3 install pyspellchecker\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, path_to_data):\n",
    "        files = []\n",
    "        tweets = pd.DataFrame()\n",
    "        for filenames in os.listdir(path_to_data):\n",
    "            if re.findall('.+\\.csv', filenames):\n",
    "                files.append(filenames)\n",
    "        for file in files:\n",
    "            with open(path_to_data + '/' + file, 'r') as f:\n",
    "                data = f.read()\n",
    "            data = re.sub(r',(?=[^ ])', '--', data)\n",
    "            df = pd.DataFrame(data.split('--'), columns=['tweets'])\n",
    "            df['category'] = file\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            tweets = tweets.append(df)\n",
    "        tweets['category'].replace({\n",
    "            'processedNegative.csv' : -1, \n",
    "            'processedNeutral.csv': 0, \n",
    "            'processedPositive.csv' : 1}, inplace=True)\n",
    "        tweets.index = np.arange(len(tweets))\n",
    "        self.tweets = tweets\n",
    "        self.spell = SpellChecker()\n",
    "\n",
    "\n",
    "    def tokenization(self):\n",
    "        array = []\n",
    "        for sent in self.tweets.tweets:\n",
    "            array.append(word_tokenize(sent))\n",
    "        self.tweets[\"just_tokenization\"] = array\n",
    "\n",
    "    def PorterStemmer(self, misspellings=False):\n",
    "        array = []\n",
    "        porter_stemmer = PorterStemmer()\n",
    "        for sent in self.tweets.tweets:\n",
    "            array.append(word_tokenize(sent))\n",
    "            for i, w in enumerate(array[-1]):\n",
    "                if (misspellings == True):\n",
    "                    array[-1][i] = self.spell.correction(w)\n",
    "                array[-1][i] = porter_stemmer.stem(w)\n",
    "    \n",
    "        if (misspellings):\n",
    "            self.tweets[\"PorterStemmer+misspellings\"] = array\n",
    "        else:\n",
    "            self.tweets[\"PorterStemmer\"] = array\n",
    "\n",
    "    def WordNetLemmatizer(self, misspellings=False):\n",
    "        nltk.download('wordnet')\n",
    "        array = []\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        for sent in self.tweets.tweets:\n",
    "            array.append(word_tokenize(sent))\n",
    "            for i, w in enumerate(array[-1]):\n",
    "                if (misspellings == True):\n",
    "                    array[-1][i] = self.spell.correction(w)\n",
    "                array[-1][i] = lemmatizer.lemmatize(w)\n",
    "                    \n",
    "        if (misspellings):\n",
    "            self.tweets[\"WordNetLemmatizer+misspellings\"] = array\n",
    "        else:\n",
    "            self.tweets[\"WordNetLemmatizer\"] = array\n",
    "\n",
    "    # def our preprocessing:\n",
    "\n",
    "        #     def remove_stopwords(text):\n",
    "        # \ttokens = word_tokenize(text.lower())\n",
    "        # \tenglish_stopwords = stopwords.words('english')\n",
    "        # \ttext = [w for w in tokens if w not in english_stopwords]\n",
    "        # \treturn \" \".join(text)\n",
    "\n",
    "        # def clear_df(text)->str:\n",
    "        # \t# text = text.lower()\n",
    "        # \ttext = contractions.fix(text)\n",
    "        # \ttext = re.sub(r'http\\S+', '', text)\n",
    "        # \ttext = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # \ttext = remove_stopwords(text)\n",
    "\n",
    "        # \treturn text\n",
    "\n",
    "        # def snowball_stemmer(text):\n",
    "        # \tstemmer = SnowballStemmer(language='english')\n",
    "        # \ttokens = word_tokenize(text.lower())\n",
    "        # \tstem_words = []\n",
    "        # \tfor w in tokens:\n",
    "        # \t\tx = stemmer.stem(w)\n",
    "        # \t\tstem_words.append(x)\n",
    "        # \treturn \" \".join(stem_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/zyxvpxvq6csfxvn_n0001wlw000g4z/T/ipykernel_74343/2485646988.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tweets = tweets.append(df)\n",
      "/var/folders/zz/zyxvpxvq6csfxvn_n0001wlw000g4z/T/ipykernel_74343/2485646988.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tweets = tweets.append(df)\n",
      "/var/folders/zz/zyxvpxvq6csfxvn_n0001wlw000g4z/T/ipykernel_74343/2485646988.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tweets = tweets.append(df)\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>category</th>\n",
       "      <th>just_tokenization</th>\n",
       "      <th>PorterStemmer</th>\n",
       "      <th>WordNetLemmatizer</th>\n",
       "      <th>WordNetLemmatizer+misspellings</th>\n",
       "      <th>PorterStemmer+misspellings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How unhappy  some dogs like it though</td>\n",
       "      <td>-1</td>\n",
       "      <td>[How, unhappy, some, dogs, like, it, though]</td>\n",
       "      <td>[how, unhappi, some, dog, like, it, though]</td>\n",
       "      <td>[How, unhappy, some, dog, like, it, though]</td>\n",
       "      <td>[How, unhappy, some, dog, like, it, though]</td>\n",
       "      <td>[how, unhappi, some, dog, like, it, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talking to my over driver about where I'm goin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[talking, to, my, over, driver, about, where, ...</td>\n",
       "      <td>[talk, to, my, over, driver, about, where, i, ...</td>\n",
       "      <td>[talking, to, my, over, driver, about, where, ...</td>\n",
       "      <td>[talking, to, my, over, driver, about, where, ...</td>\n",
       "      <td>[talk, to, my, over, driver, about, where, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does anybody know if the Rand's likely to fall...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Does, anybody, know, if, the, Rand, 's, likel...</td>\n",
       "      <td>[doe, anybodi, know, if, the, rand, 's, like, ...</td>\n",
       "      <td>[Does, anybody, know, if, the, Rand, 's, likel...</td>\n",
       "      <td>[Does, anybody, know, if, the, Rand, 's, likel...</td>\n",
       "      <td>[doe, anybodi, know, if, the, rand, 's, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I miss going to gigs in Liverpool unhappy</td>\n",
       "      <td>-1</td>\n",
       "      <td>[I, miss, going, to, gigs, in, Liverpool, unha...</td>\n",
       "      <td>[i, miss, go, to, gig, in, liverpool, unhappi]</td>\n",
       "      <td>[I, miss, going, to, gig, in, Liverpool, unhappy]</td>\n",
       "      <td>[I, miss, going, to, gig, in, Liverpool, unhappy]</td>\n",
       "      <td>[i, miss, go, to, gig, in, liverpool, unhappi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There isnt a new Riverdale tonight ? unhappy</td>\n",
       "      <td>-1</td>\n",
       "      <td>[There, isnt, a, new, Riverdale, tonight, ?, u...</td>\n",
       "      <td>[there, isnt, a, new, riverdal, tonight, ?, un...</td>\n",
       "      <td>[There, isnt, a, new, Riverdale, tonight, ?, u...</td>\n",
       "      <td>[There, isnt, a, new, Riverdale, tonight, ?, u...</td>\n",
       "      <td>[there, isnt, a, new, riverdal, tonight, ?, un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>$ES_F $SPY  Bulls are just relentless  happy  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[$, ES_F, $, SPY, Bulls, are, just, relentless...</td>\n",
       "      <td>[$, es_f, $, spi, bull, are, just, relentless,...</td>\n",
       "      <td>[$, ES_F, $, SPY, Bulls, are, just, relentless...</td>\n",
       "      <td>[$, ES_F, $, SPY, Bulls, are, just, relentless...</td>\n",
       "      <td>[$, es_f, $, spi, bull, are, just, relentless,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>you know that the problem still exist :D</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>- top engaged members this week happy</td>\n",
       "      <td>1</td>\n",
       "      <td>[-, top, engaged, members, this, week, happy]</td>\n",
       "      <td>[-, top, engag, member, thi, week, happi]</td>\n",
       "      <td>[-, top, engaged, member, this, week, happy]</td>\n",
       "      <td>[-, top, engaged, member, this, week, happy]</td>\n",
       "      <td>[-, top, engag, member, thi, week, happi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>ngam to  weeks left for cadet pilot exam cryin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ngam, to, weeks, left, for, cadet, pilot, exa...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Great! You're welcome Josh happy  ^Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, !, You, 're, welcome, Josh, happy, ^Adam]</td>\n",
       "      <td>[great, !, you, 're, welcom, josh, happi, ^adam]</td>\n",
       "      <td>[Great, !, You, 're, welcome, Josh, happy, ^Adam]</td>\n",
       "      <td>[Great, !, You, 're, welcome, Josh, happy, ^Adam]</td>\n",
       "      <td>[great, !, you, 're, welcom, josh, happi, ^adam]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2745 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  category  \\\n",
       "0                 How unhappy  some dogs like it though        -1   \n",
       "1     talking to my over driver about where I'm goin...        -1   \n",
       "2     Does anybody know if the Rand's likely to fall...        -1   \n",
       "3            I miss going to gigs in Liverpool unhappy         -1   \n",
       "4         There isnt a new Riverdale tonight ? unhappy         -1   \n",
       "...                                                 ...       ...   \n",
       "2740  $ES_F $SPY  Bulls are just relentless  happy  ...         1   \n",
       "2741           you know that the problem still exist :D         1   \n",
       "2742              - top engaged members this week happy         1   \n",
       "2743  ngam to  weeks left for cadet pilot exam cryin...         1   \n",
       "2744            Great! You're welcome Josh happy  ^Adam         1   \n",
       "\n",
       "                                      just_tokenization  \\\n",
       "0          [How, unhappy, some, dogs, like, it, though]   \n",
       "1     [talking, to, my, over, driver, about, where, ...   \n",
       "2     [Does, anybody, know, if, the, Rand, 's, likel...   \n",
       "3     [I, miss, going, to, gigs, in, Liverpool, unha...   \n",
       "4     [There, isnt, a, new, Riverdale, tonight, ?, u...   \n",
       "...                                                 ...   \n",
       "2740  [$, ES_F, $, SPY, Bulls, are, just, relentless...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742      [-, top, engaged, members, this, week, happy]   \n",
       "2743  [ngam, to, weeks, left, for, cadet, pilot, exa...   \n",
       "2744  [Great, !, You, 're, welcome, Josh, happy, ^Adam]   \n",
       "\n",
       "                                          PorterStemmer  \\\n",
       "0           [how, unhappi, some, dog, like, it, though]   \n",
       "1     [talk, to, my, over, driver, about, where, i, ...   \n",
       "2     [doe, anybodi, know, if, the, rand, 's, like, ...   \n",
       "3        [i, miss, go, to, gig, in, liverpool, unhappi]   \n",
       "4     [there, isnt, a, new, riverdal, tonight, ?, un...   \n",
       "...                                                 ...   \n",
       "2740  [$, es_f, $, spi, bull, are, just, relentless,...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742          [-, top, engag, member, thi, week, happi]   \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...   \n",
       "2744   [great, !, you, 're, welcom, josh, happi, ^adam]   \n",
       "\n",
       "                                      WordNetLemmatizer  \\\n",
       "0           [How, unhappy, some, dog, like, it, though]   \n",
       "1     [talking, to, my, over, driver, about, where, ...   \n",
       "2     [Does, anybody, know, if, the, Rand, 's, likel...   \n",
       "3     [I, miss, going, to, gig, in, Liverpool, unhappy]   \n",
       "4     [There, isnt, a, new, Riverdale, tonight, ?, u...   \n",
       "...                                                 ...   \n",
       "2740  [$, ES_F, $, SPY, Bulls, are, just, relentless...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742       [-, top, engaged, member, this, week, happy]   \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...   \n",
       "2744  [Great, !, You, 're, welcome, Josh, happy, ^Adam]   \n",
       "\n",
       "                         WordNetLemmatizer+misspellings  \\\n",
       "0           [How, unhappy, some, dog, like, it, though]   \n",
       "1     [talking, to, my, over, driver, about, where, ...   \n",
       "2     [Does, anybody, know, if, the, Rand, 's, likel...   \n",
       "3     [I, miss, going, to, gig, in, Liverpool, unhappy]   \n",
       "4     [There, isnt, a, new, Riverdale, tonight, ?, u...   \n",
       "...                                                 ...   \n",
       "2740  [$, ES_F, $, SPY, Bulls, are, just, relentless...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742       [-, top, engaged, member, this, week, happy]   \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...   \n",
       "2744  [Great, !, You, 're, welcome, Josh, happy, ^Adam]   \n",
       "\n",
       "                             PorterStemmer+misspellings  \n",
       "0           [how, unhappi, some, dog, like, it, though]  \n",
       "1     [talk, to, my, over, driver, about, where, i, ...  \n",
       "2     [doe, anybodi, know, if, the, rand, 's, like, ...  \n",
       "3        [i, miss, go, to, gig, in, liverpool, unhappi]  \n",
       "4     [there, isnt, a, new, riverdal, tonight, ?, un...  \n",
       "...                                                 ...  \n",
       "2740  [$, es_f, $, spi, bull, are, just, relentless,...  \n",
       "2741  [you, know, that, the, problem, still, exist, ...  \n",
       "2742          [-, top, engag, member, thi, week, happi]  \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...  \n",
       "2744   [great, !, you, 're, welcom, josh, happi, ^adam]  \n",
       "\n",
       "[2745 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#минут 6 учицца - норма\n",
    "preproc = Preprocessing(\"./data\")\n",
    "preproc.tokenization()\n",
    "preproc.PorterStemmer(False)\n",
    "preproc.WordNetLemmatizer(False)\n",
    "preproc.WordNetLemmatizer(True)\n",
    "preproc.PorterStemmer(True)\n",
    "preproc_data = preproc.tweets\n",
    "preproc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>category</th>\n",
       "      <th>just_tokenization</th>\n",
       "      <th>PorterStemmer</th>\n",
       "      <th>WordNetLemmatizer</th>\n",
       "      <th>WordNetLemmatizer+misspellings</th>\n",
       "      <th>PorterStemmer+misspellings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How unhappy  some dogs like it though</td>\n",
       "      <td>-1</td>\n",
       "      <td>[How, unhappy, some, dogs, like, it, though]</td>\n",
       "      <td>[how, unhappi, some, dog, like, it, though]</td>\n",
       "      <td>[How, unhappy, some, dog, like, it, though]</td>\n",
       "      <td>[How, unhappy, some, dog, like, it, though]</td>\n",
       "      <td>[how, unhappi, some, dog, like, it, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talking to my over driver about where I'm goin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[talking, to, my, over, driver, about, where, ...</td>\n",
       "      <td>[talk, to, my, over, driver, about, where, i, ...</td>\n",
       "      <td>[talking, to, my, over, driver, about, where, ...</td>\n",
       "      <td>[talking, to, my, over, driver, about, where, ...</td>\n",
       "      <td>[talk, to, my, over, driver, about, where, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does anybody know if the Rand's likely to fall...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[Does, anybody, know, if, the, Rand, 's, likel...</td>\n",
       "      <td>[doe, anybodi, know, if, the, rand, 's, like, ...</td>\n",
       "      <td>[Does, anybody, know, if, the, Rand, 's, likel...</td>\n",
       "      <td>[Does, anybody, know, if, the, Rand, 's, likel...</td>\n",
       "      <td>[doe, anybodi, know, if, the, rand, 's, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I miss going to gigs in Liverpool unhappy</td>\n",
       "      <td>-1</td>\n",
       "      <td>[I, miss, going, to, gigs, in, Liverpool, unha...</td>\n",
       "      <td>[i, miss, go, to, gig, in, liverpool, unhappi]</td>\n",
       "      <td>[I, miss, going, to, gig, in, Liverpool, unhappy]</td>\n",
       "      <td>[I, miss, going, to, gig, in, Liverpool, unhappy]</td>\n",
       "      <td>[i, miss, go, to, gig, in, liverpool, unhappi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There isnt a new Riverdale tonight ? unhappy</td>\n",
       "      <td>-1</td>\n",
       "      <td>[There, isnt, a, new, Riverdale, tonight, ?, u...</td>\n",
       "      <td>[there, isnt, a, new, riverdal, tonight, ?, un...</td>\n",
       "      <td>[There, isnt, a, new, Riverdale, tonight, ?, u...</td>\n",
       "      <td>[There, isnt, a, new, Riverdale, tonight, ?, u...</td>\n",
       "      <td>[there, isnt, a, new, riverdal, tonight, ?, un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>$ES_F $SPY  Bulls are just relentless  happy  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[$, ES_F, $, SPY, Bulls, are, just, relentless...</td>\n",
       "      <td>[$, es_f, $, spi, bull, are, just, relentless,...</td>\n",
       "      <td>[$, ES_F, $, SPY, Bulls, are, just, relentless...</td>\n",
       "      <td>[$, ES_F, $, SPY, Bulls, are, just, relentless...</td>\n",
       "      <td>[$, es_f, $, spi, bull, are, just, relentless,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>you know that the problem still exist :D</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "      <td>[you, know, that, the, problem, still, exist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>- top engaged members this week happy</td>\n",
       "      <td>1</td>\n",
       "      <td>[-, top, engaged, members, this, week, happy]</td>\n",
       "      <td>[-, top, engag, member, thi, week, happi]</td>\n",
       "      <td>[-, top, engaged, member, this, week, happy]</td>\n",
       "      <td>[-, top, engaged, member, this, week, happy]</td>\n",
       "      <td>[-, top, engag, member, thi, week, happi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>ngam to  weeks left for cadet pilot exam cryin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ngam, to, weeks, left, for, cadet, pilot, exa...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "      <td>[ngam, to, week, left, for, cadet, pilot, exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Great! You're welcome Josh happy  ^Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, !, You, 're, welcome, Josh, happy, ^Adam]</td>\n",
       "      <td>[great, !, you, 're, welcom, josh, happi, ^adam]</td>\n",
       "      <td>[Great, !, You, 're, welcome, Josh, happy, ^Adam]</td>\n",
       "      <td>[Great, !, You, 're, welcome, Josh, happy, ^Adam]</td>\n",
       "      <td>[great, !, you, 're, welcom, josh, happi, ^adam]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2745 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  category  \\\n",
       "0                 How unhappy  some dogs like it though        -1   \n",
       "1     talking to my over driver about where I'm goin...        -1   \n",
       "2     Does anybody know if the Rand's likely to fall...        -1   \n",
       "3            I miss going to gigs in Liverpool unhappy         -1   \n",
       "4         There isnt a new Riverdale tonight ? unhappy         -1   \n",
       "...                                                 ...       ...   \n",
       "2740  $ES_F $SPY  Bulls are just relentless  happy  ...         1   \n",
       "2741           you know that the problem still exist :D         1   \n",
       "2742              - top engaged members this week happy         1   \n",
       "2743  ngam to  weeks left for cadet pilot exam cryin...         1   \n",
       "2744            Great! You're welcome Josh happy  ^Adam         1   \n",
       "\n",
       "                                      just_tokenization  \\\n",
       "0          [How, unhappy, some, dogs, like, it, though]   \n",
       "1     [talking, to, my, over, driver, about, where, ...   \n",
       "2     [Does, anybody, know, if, the, Rand, 's, likel...   \n",
       "3     [I, miss, going, to, gigs, in, Liverpool, unha...   \n",
       "4     [There, isnt, a, new, Riverdale, tonight, ?, u...   \n",
       "...                                                 ...   \n",
       "2740  [$, ES_F, $, SPY, Bulls, are, just, relentless...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742      [-, top, engaged, members, this, week, happy]   \n",
       "2743  [ngam, to, weeks, left, for, cadet, pilot, exa...   \n",
       "2744  [Great, !, You, 're, welcome, Josh, happy, ^Adam]   \n",
       "\n",
       "                                          PorterStemmer  \\\n",
       "0           [how, unhappi, some, dog, like, it, though]   \n",
       "1     [talk, to, my, over, driver, about, where, i, ...   \n",
       "2     [doe, anybodi, know, if, the, rand, 's, like, ...   \n",
       "3        [i, miss, go, to, gig, in, liverpool, unhappi]   \n",
       "4     [there, isnt, a, new, riverdal, tonight, ?, un...   \n",
       "...                                                 ...   \n",
       "2740  [$, es_f, $, spi, bull, are, just, relentless,...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742          [-, top, engag, member, thi, week, happi]   \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...   \n",
       "2744   [great, !, you, 're, welcom, josh, happi, ^adam]   \n",
       "\n",
       "                                      WordNetLemmatizer  \\\n",
       "0           [How, unhappy, some, dog, like, it, though]   \n",
       "1     [talking, to, my, over, driver, about, where, ...   \n",
       "2     [Does, anybody, know, if, the, Rand, 's, likel...   \n",
       "3     [I, miss, going, to, gig, in, Liverpool, unhappy]   \n",
       "4     [There, isnt, a, new, Riverdale, tonight, ?, u...   \n",
       "...                                                 ...   \n",
       "2740  [$, ES_F, $, SPY, Bulls, are, just, relentless...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742       [-, top, engaged, member, this, week, happy]   \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...   \n",
       "2744  [Great, !, You, 're, welcome, Josh, happy, ^Adam]   \n",
       "\n",
       "                         WordNetLemmatizer+misspellings  \\\n",
       "0           [How, unhappy, some, dog, like, it, though]   \n",
       "1     [talking, to, my, over, driver, about, where, ...   \n",
       "2     [Does, anybody, know, if, the, Rand, 's, likel...   \n",
       "3     [I, miss, going, to, gig, in, Liverpool, unhappy]   \n",
       "4     [There, isnt, a, new, Riverdale, tonight, ?, u...   \n",
       "...                                                 ...   \n",
       "2740  [$, ES_F, $, SPY, Bulls, are, just, relentless...   \n",
       "2741  [you, know, that, the, problem, still, exist, ...   \n",
       "2742       [-, top, engaged, member, this, week, happy]   \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...   \n",
       "2744  [Great, !, You, 're, welcome, Josh, happy, ^Adam]   \n",
       "\n",
       "                             PorterStemmer+misspellings  \n",
       "0           [how, unhappi, some, dog, like, it, though]  \n",
       "1     [talk, to, my, over, driver, about, where, i, ...  \n",
       "2     [doe, anybodi, know, if, the, rand, 's, like, ...  \n",
       "3        [i, miss, go, to, gig, in, liverpool, unhappi]  \n",
       "4     [there, isnt, a, new, riverdal, tonight, ?, un...  \n",
       "...                                                 ...  \n",
       "2740  [$, es_f, $, spi, bull, are, just, relentless,...  \n",
       "2741  [you, know, that, the, problem, still, exist, ...  \n",
       "2742          [-, top, engag, member, thi, week, happi]  \n",
       "2743  [ngam, to, week, left, for, cadet, pilot, exam...  \n",
       "2744   [great, !, you, 're, welcom, josh, happi, ^adam]  \n",
       "\n",
       "[2745 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TO_VEC:\n",
    "    def __init__(self, data_frame):\n",
    "        self.text = data_frame\n",
    "        self.vectors = pd.DataFrame()\n",
    "\n",
    "    def to_bin_vec(self):\n",
    "        coun_vect = CountVectorizer(binary=True)\n",
    "        for i in range(self.text.shape[1]):\n",
    "            if i == 1: continue #костыль чтобы игнорить target столбец\n",
    "            text = pd.DataFrame(map(lambda x: ' '.join(x), self.text.iloc[:,2])).iloc[:, 0].tolist()\n",
    "            name = self.text.iloc[:,i].name\n",
    "            count_matrix = coun_vect.fit_transform(text)\n",
    "            count_array = count_matrix.toarray()\n",
    "            self.vectors[\"bin_vec_{}\".format(name)] = list(count_array)\n",
    "\n",
    "    def to_TFIDF(self):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        for i in range(self.text.shape[1]):\n",
    "            if i == 1: continue #костыль чтобы игнорить target столбец\n",
    "            text = pd.DataFrame(map(lambda x: ' '.join(x), self.text.iloc[:,2])).iloc[:, 0].tolist()\n",
    "            name = self.text.iloc[:,i].name\n",
    "            count_matrix = vectorizer.fit_transform(text)\n",
    "            count_array = count_matrix.toarray()\n",
    "            self.vectors[\"TFIDF_{}\".format(name)] = list(count_array)\n",
    "\n",
    "    def to_word_counts(self):\n",
    "        coun_vect = CountVectorizer()\n",
    "        for i in range(self.text.shape[1]):\n",
    "            if i == 1: continue #костыль чтобы игнорить target столбец\n",
    "            text = pd.DataFrame(map(lambda x: ' '.join(x), self.text.iloc[:,2])).iloc[:, 0].tolist()\n",
    "            name = self.text.iloc[:,i].name\n",
    "            count_matrix = coun_vect.fit_transform(text)\n",
    "            count_array = count_matrix.toarray()\n",
    "            self.vectors[\"word_counts_{}\".format(name)] = list(count_array)\n",
    "\n",
    "\n",
    "    # def to_wordtovec:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = TO_VEC(preproc_data)\n",
    "vectors.to_bin_vec()\n",
    "vectors.to_TFIDF()\n",
    "vectors.to_word_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_vec_tweets</th>\n",
       "      <th>bin_vec_just_tokenization</th>\n",
       "      <th>bin_vec_PorterStemmer</th>\n",
       "      <th>bin_vec_WordNetLemmatizer</th>\n",
       "      <th>bin_vec_WordNetLemmatizer+misspellings</th>\n",
       "      <th>bin_vec_PorterStemmer+misspellings</th>\n",
       "      <th>TFIDF_tweets</th>\n",
       "      <th>TFIDF_just_tokenization</th>\n",
       "      <th>TFIDF_PorterStemmer</th>\n",
       "      <th>TFIDF_WordNetLemmatizer</th>\n",
       "      <th>TFIDF_WordNetLemmatizer+misspellings</th>\n",
       "      <th>TFIDF_PorterStemmer+misspellings</th>\n",
       "      <th>word_counts_tweets</th>\n",
       "      <th>word_counts_just_tokenization</th>\n",
       "      <th>word_counts_PorterStemmer</th>\n",
       "      <th>word_counts_WordNetLemmatizer</th>\n",
       "      <th>word_counts_WordNetLemmatizer+misspellings</th>\n",
       "      <th>word_counts_PorterStemmer+misspellings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2745 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         bin_vec_tweets  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                              bin_vec_just_tokenization  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                  bin_vec_PorterStemmer  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                              bin_vec_WordNetLemmatizer  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                 bin_vec_WordNetLemmatizer+misspellings  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                     bin_vec_PorterStemmer+misspellings  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           TFIDF_tweets  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2742  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2744  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                TFIDF_just_tokenization  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2742  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2744  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                    TFIDF_PorterStemmer  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2742  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2744  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                TFIDF_WordNetLemmatizer  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2742  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2744  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                   TFIDF_WordNetLemmatizer+misspellings  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2742  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2744  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                       TFIDF_PorterStemmer+misspellings  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2741  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2742  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2743  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2744  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     word_counts_tweets  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                          word_counts_just_tokenization  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                              word_counts_PorterStemmer  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                          word_counts_WordNetLemmatizer  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "             word_counts_WordNetLemmatizer+misspellings  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                 word_counts_PorterStemmer+misspellings  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2740  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2741  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2742  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2743  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2744  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2745 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectors.vectors.iloc[:,2]\n",
    "y = preproc_data.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.8, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.tolist())\n",
    "X_test = pd.DataFrame(X_test.tolist())\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034608378870674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "predict = clf.predict(X_test)\n",
    "accuracy_score(predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_data = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "# lr_data.fit(tfidf_train_data, y_train)\n",
    "# tfidf_pred_data = lr_data.predict(tfidf_test_data)\n",
    "# print('test')\n",
    "# print(classification_report(y_test, tfidf_pred_data))\n",
    "# print('train')\n",
    "# print(classification_report(y_train, lr_data.predict(tfidf_train_data)))\n",
    "\n",
    "# def plot_conf_matrix(true, pred, cat=['-1', '0', '1']):\n",
    "#     sns.heatmap(data=confusion_matrix(true, pred), \n",
    "#             annot=True, fmt=\"d\", cbar=False, xticklabels=cat, yticklabels=cat)\n",
    "\n",
    "\n",
    "# plot_conf_matrix(y_test, tfidf_pred_data)\n",
    "\n",
    "# accuracy_score(y_test, tfidf_pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASHE::\n",
    "\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "# data_neg = list(csv.reader(open(\"data/processedNegative.csv\"), delimiter=','))[0]\n",
    "# data_pos = list(csv.reader(open(\"data/processedNeutral.csv\"), delimiter=','))[0]\n",
    "# data_neut = list(csv.reader(open(\"data/processedPositive.csv\"), delimiter=','))[0]\n",
    "\n",
    "# X = data_neg + data_pos + data_neut\n",
    "# y = list(np.ones(len(data_neg)) * 0) + list(np.ones(len(data_pos)))  +  list(np.ones(len(data_neut)) * 2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
